关于打造自己的 AI 工作流的一些科普

有很多朋友都在尝试各种各样的AI工具，但通常都会在配置时，遇到一个同类问题，就是API KEY到底从哪儿来，到底怎么配置。今天我们就来再梳理一下。

AI应用可以分为两个大类：一是模型开发商发布的应用，包括ChatGPT、Claude(chat)、智谱清言、kimi、豆包、天宫、通义、文心一言、腾讯元宝等等；二是调用其他模型的API来完成自身功能的应用，例如秘塔搜索、perplexity、沉浸式翻译、Gamma、Dify、扣子、得到AI助手、gru.ai、Open Interpreter、fabric等等，部分应用王树义老师之前已经介绍过。

对于第一类应用，通常会出一个会员，按月或者按年收费。
对于第二类应用，又分为两种，一种是打包收会员费的，他去模型厂商那里批发模型推理能力，然后叠加上自己的功能零售给你，比如perplexity、Gamma、gru.ai，当然也可能暂时不收费；第二种是只提供应用框架，你需要自己去采购大模型的推理能力，然后交给他来调用，比如fabric、Open Interpreter。当然也有的应用是两种方案都有，比如沉浸式翻译，Dify等等。

所谓的配置AI工具，就更多地是指的上面第二种，你去大模型厂商那里买推理能力。大模型提供推理能力的方式被称为API，为了让应用更容易调用API，所以模型厂商又封装了自己的开发工具包（SDK），例如，最有名的就是OpenAI的python包，其名称就叫做openai。openai包在使用时，为了避免把重要的参数硬编码在应用中，所以会读取两个重要的环境变量来设置自己的参数。这两个环境变量分别是：
OPENAI_API_KEY
OPENAI_BASE_URL

这就引出了两个重要的参数：API KEY 和 Base URL。

API KEY是一串你的专属密码，你去大模型厂商那里买了推理能力，别人就会给你（或者你自己生成），证明你是你，用你通过这个密码而调用的数量，给你计费。形如：sk-xxxxxxxxxxxxxxxxxxxxxx

Base URL是API的服务器地址，可以简单的理解，我们与模型对话，这个对话要发给哪个网址。这个网址可以在大模型厂商的说明文档中找到，一般都在API的版块中有说明，或者是在示例代码中会出现。例如：
OpenAI：https://api.openai.com/v1
OpenRouter：https://openrouter.ai/api/v1
智谱AI：https://open.bigmodel.cn/api/paas/v4/

还有一个重要的参数：Model模型，具体使用哪一个模型来进行推理。举个例子，Base URL是指具体进哪个房间，API Key是这个房间的钥匙，而Model是进了房间后看哪本书。模型名称例如：gpt-4o，gpt-4-turbo，gpt-4o-mini，claude-3-5-sonnet，openai/gpt-4o-mini等等，注意命名完全是由供应商来定义的，哪怕同一个模型，在不同的供应商那里，名称也可能不一样。

把获得的API Key和Base URL写入到环境变量OPENAI_API_KEY和OPENAI_BASE_URL中，openai包就可以顺利运行了。

那么问题来了：
问题1：不是从OpenAI上买的大模型API怎么办呢？
没事，大模型的厂商，大多数都对openai的包进行了兼容，也就是说，只要是使用openai包的应用程序，你只需要配置好OPENAI_API_KEY、OPENAI_BASE_URL和模型名称就行。

问题2：哪里可以买到大模型的推理能力（或者API）呢？
大模型的API一般可以通过两类途径购买到（或者免费获得）。
途径一：官方网站。OpenAI、Claude、智谱AI、moonshot、零一等等，这些模型的生产方都有在线销售渠道。缺点是，除了一些开源模型，自家的模型一般只能从自家购买，也就是说，充值的话，得在多家充值。
途径二：集成商。有不少直接把众多大模型的接口集中起来，统一提供的厂商，在这一家充值，就能够使用很多家的大模型。其中使用最多的是OpenRouter，他可以提供GPT和Claude模型，以及其他几乎所有能够想到的模型，其他的还有SiliconFlow和Groq，主要提供开源模型的在线使用。这些集成商几乎也都提供与openai包的兼容模式。

上结论：
由于各个大模型厂商和集成服务商，大都做了与OpenAI的API协议兼容，所以，使用时，配置也是对OpenAI的参数、环境变量进行配置，这一点不用再感到诧异了。
对于需要由用户自己提供大模型推理能力的应用，用户可以选择去 大模型的官方网站 或者 大模型服务集成商 去充值获得推理服务的额度，一定要获得三个重要的参数：BaseURL、API Key、Model名称。如果是图形化界面的应用，找到配置项：如果配置项中直接有咱们充值的模型提供商（例如Dify），选择它进行配置这三个参数；如果应用没有区分，那么选择OpenAI，然后正确配置上面三个参数即可。如果是命令行的应用（例如fabric），查看官方文档，如果没有特殊说明，那么这个应用大概率是使用的openai的库，直接设置OPENAI_API_KEY和OPENAI_BASE_URL环境变量，然后找到模型名称的传递参数方式即可。